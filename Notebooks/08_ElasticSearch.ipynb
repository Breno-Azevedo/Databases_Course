{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Databases\n",
    "\n",
    "### Using elasticsearch\n",
    "\n",
    "Based on [this](https://medium.com/naukri-engineering/elasticsearch-tutorial-for-beginners-using-python-b9cb48edcedc), [this](https://towardsdatascience.com/getting-started-with-elasticsearch-in-python-c3598e718380) and [this](https://www.elastic.co/guide/en/elasticsearch/reference/current/elasticsearch-intro.html) posts  \n",
    "\n",
    "[Installing Elastic Search](https://www.elastic.co/guide/en/elasticsearch/reference/current/install-elasticsearch.html)  \n",
    "\n",
    "To install the Python wrapper, run:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!sudo pip install -U elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"error\":{\"root_cause\":[{\"type\":\"index_not_found_exception\",\"reason\":\"no such index\",\"resource.type\":\"index_expression\",\"resource.id\":\"_all\"}],\"type\":\"index_not_found_exception\",\"reason\":\"no such index\",\"resource.type\":\"index_expression\",\"resource.id\":\"_all\"},\"status\":404}"
     ]
    }
   ],
   "source": [
    "!curl -XPUT -H \"Content-Type: application/json\" http://localhost:9200/_all/_settings -d '{\"index.blocks.read_only_allow_delete\": null}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import logging\n",
    "from time import sleep\n",
    "import requests\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cluster_name': 'elasticsearch',\n",
      " 'cluster_uuid': 'ZV9z9yl4SVa861af9CnG7A',\n",
      " 'name': 'AMYiWlv',\n",
      " 'tagline': 'You Know, for Search',\n",
      " 'version': {'build_date': '2020-10-16T09:09:46.555371Z',\n",
      "             'build_flavor': 'default',\n",
      "             'build_hash': 'be13c69',\n",
      "             'build_snapshot': False,\n",
      "             'build_type': 'deb',\n",
      "             'lucene_version': '7.7.3',\n",
      "             'minimum_index_compatibility_version': '5.0.0',\n",
      "             'minimum_wire_compatibility_version': '5.6.0',\n",
      "             'number': '6.8.13'}}\n"
     ]
    }
   ],
   "source": [
    "res = requests.get('http://localhost:9200')\n",
    "pprint(res.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Elasticsearch?\n",
    "\n",
    "Elasticsearch is the distributed search and analytics engine at the heart of the [Elastic Stack](https://www.elastic.co/pt/elk-stack). \n",
    "\n",
    "Elasticsearch provides near real-time search and analytics for all types of data. Whether you have structured or unstructured text, numerical data, or geospatial data, Elasticsearch can efficiently store and index it in a way that supports fast searches. You can go far beyond simple data retrieval and aggregate information to discover trends and patterns in your data. And as your data and query volume grows, the distributed nature of Elasticsearch enables your deployment to grow seamlessly right along with it.\n",
    "\n",
    "While not every problem is a search problem, Elasticsearch offers speed and flexibility to handle data in a wide variety of use cases:\n",
    "\n",
    "+ Add a search box to an app or website\n",
    "+ Store and analyze logs, metrics, and security event data\n",
    "+ Use machine learning to automatically model the behavior of your data in real time\n",
    "+ Automate business workflows using Elasticsearch as a storage engine\n",
    "+ Manage, integrate, and analyze spatial information using Elasticsearch as a geographic information system (GIS)\n",
    "+ ore and process genetic data using Elasticsearch as a bioinformatics research tool\n",
    "\n",
    "We’re continually amazed by the novel ways people use search. But whether your use case is similar to one of these, or you’re using Elasticsearch to tackle a new problem, the way you work with your data, documents, and indices in Elasticsearch is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Elasticsearch([{'host': 'localhost', 'port': 9200}])>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to the elastic cluster\n",
    "es = Elasticsearch([{'host':'localhost','port':9200}])\n",
    "es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elasticsearch is document oriented, meaning that it stores entire object or documents. It not only stores them, but also indexes the content of each document in order to make them searchable. In Elasticsearch you index, search,sort and filter documents.\n",
    "\n",
    "Elasticsearch uses JSON as the serialisation format for the documents.\n",
    "\n",
    "Now let’s start by indexing the employee documents.\n",
    "\n",
    "The act of storing data in Elasticsearch is called indexing. An Elasticsearch cluster can contain multiple indices, which in turn contain multiple types. These types hold multiple documents, and each document has multiple fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"about\": \"I love to climb\",\n",
      "  \"age\": 30,\n",
      "  \"first_name\": \"Renato\",\n",
      "  \"interests\": [\n",
      "    \"sports\",\n",
      "    \"music\",\n",
      "    \"literature\"\n",
      "  ],\n",
      "  \"last_name\": \"Souza\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "e1 = {\"first_name\":\"Renato\",\n",
    "      \"last_name\":\"Souza\",\n",
    "      \"age\": 30,\n",
    "      \"about\": \"I love to climb\",\n",
    "      \"interests\": ['sports','music','literature'],\n",
    "     }\n",
    "\n",
    "print(json.dumps(e1, indent=2, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting a document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rsouza/Documents/envs/new_env/lib/python3.8/site-packages/elasticsearch/connection/base.py:209: ElasticsearchWarning: the default number of shards will change from [5] to [1] in 7.0.0; if you wish to continue using the default of [5] shards, you must manage this on the create index request or with an index template\n",
      "  warnings.warn(message, category=ElasticsearchWarning)\n"
     ]
    }
   ],
   "source": [
    "#Now let's store this document in Elasticsearch \n",
    "\n",
    "res = es.index(index='emap',\n",
    "               doc_type='employee',\n",
    "               id=1,\n",
    "               document=e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"_id\": \"2\",\n",
      "  \"_index\": \"emap\",\n",
      "  \"_primary_term\": 1,\n",
      "  \"_seq_no\": 0,\n",
      "  \"_shards\": {\n",
      "    \"failed\": 0,\n",
      "    \"successful\": 1,\n",
      "    \"total\": 2\n",
      "  },\n",
      "  \"_type\": \"employee\",\n",
      "  \"_version\": 1,\n",
      "  \"result\": \"created\"\n",
      "}\n",
      "{\n",
      "  \"_id\": \"3\",\n",
      "  \"_index\": \"emap\",\n",
      "  \"_primary_term\": 1,\n",
      "  \"_seq_no\": 0,\n",
      "  \"_shards\": {\n",
      "    \"failed\": 0,\n",
      "    \"successful\": 1,\n",
      "    \"total\": 2\n",
      "  },\n",
      "  \"_type\": \"employee\",\n",
      "  \"_version\": 1,\n",
      "  \"result\": \"created\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Let's insert some more documents\n",
    "e2 = {\"first_name\" :  \"Leonardo\",\n",
    "      \"last_name\" :   \"Smith\",\n",
    "      \"age\" :         32,\n",
    "      \"about\" :       \"I like to collect rock albums\",\n",
    "      \"interests\":  [\"music\"]\n",
    "     }\n",
    "\n",
    "e3 = {\"first_name\" :  \"Pedro\",\n",
    "      \"last_name\" :   \"Clark\",\n",
    "      \"age\" :         35,\n",
    "      \"about\":        \"I like to build cabinets\",\n",
    "      \"interests\":  [\"forestry\"]}\n",
    "\n",
    "res = es.index(index='emap',\n",
    "               doc_type='employee',\n",
    "               id=2,\n",
    "               document=e2)\n",
    "\n",
    "print(json.dumps(res, indent=2, sort_keys=True))\n",
    "\n",
    "res = es.index(index='emap',\n",
    "               doc_type='employee',\n",
    "               id=3,\n",
    "               document=e3)\n",
    "\n",
    "print(json.dumps(res, indent=2, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving a Document:\n",
    "\n",
    "This is easy in Elasticsearch. We simply execute an HTTP GET request and specify the address of the document — the index, type, and ID. Using those three pieces of information, we can return the original JSON document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"_id\": \"2\",\n",
      "  \"_index\": \"emap\",\n",
      "  \"_primary_term\": 1,\n",
      "  \"_seq_no\": 0,\n",
      "  \"_source\": {\n",
      "    \"about\": \"I like to collect rock albums\",\n",
      "    \"age\": 32,\n",
      "    \"first_name\": \"Leonardo\",\n",
      "    \"interests\": [\n",
      "      \"music\"\n",
      "    ],\n",
      "    \"last_name\": \"Smith\"\n",
      "  },\n",
      "  \"_type\": \"employee\",\n",
      "  \"_version\": 1,\n",
      "  \"found\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "res = es.get(index='emap',\n",
    "             doc_type='employee',\n",
    "             id=2)\n",
    "\n",
    "print(json.dumps(res, indent=2, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will get the actual document in ‘_source’ field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_name': 'Leonardo',\n",
       " 'last_name': 'Smith',\n",
       " 'age': 32,\n",
       " 'about': 'I like to collect rock albums',\n",
       " 'interests': ['music']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['_source']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting a document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted\n"
     ]
    }
   ],
   "source": [
    "res = es.delete(index='emap',\n",
    "                doc_type='employee',\n",
    "                id=1)\n",
    "\n",
    "print(res['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s validate the absence of the document in Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 0 hits:\n"
     ]
    }
   ],
   "source": [
    "res = es.search(index='emap',\n",
    "                query={'match_all':{}})\n",
    "\n",
    "print('Got %d hits:' %res['hits']['total'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Lite:\n",
    "\n",
    "A GET is fairly simple — you get back the document that you ask for. Let’s try something a little more advanced, like a simple search! \n",
    "\n",
    "[Ref](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-bool-query.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "res = es.search(index='emap',\n",
    "                query={<your query comes here>})\n",
    "\n",
    "print(json.dumps(res['hits']['hits'], indent=2, sort_keys=True))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s search for the user name who has nitin in his first name.\n",
    "\n",
    "### match operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "res = es.search(index='emap',\n",
    "                query={'match':{'first_name':'Pedro'}})\n",
    "\n",
    "print(json.dumps(res['hits']['hits'], indent=2, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bool operator:\n",
    "\n",
    "bool takes a dictionary containing at least one of must, should, and must_not, each of which takes a list of matches or other further search operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "res = es.search(index='emap',\n",
    "                query={'bool':{'must':[{'match':{'first_name':'Leonardo'}}]}}\n",
    "               )\n",
    "print(json.dumps(res['hits']['hits'], indent=2, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter operator:\n",
    "\n",
    "Let’s make the search a little more complicated. We still want to find all employees with a first name of nitin, but we want only employees who are older than 30. Our query will change a little to accommodate a filter, which allows us to execute structured searches efficiently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "res= es.search(index='emap',\n",
    "               query={'bool':{'must':{'match':{'first_name':'Pedro'}},\n",
    "                              'filter':{\"range\":{\"age\":{\"gt\":25}}}}\n",
    "                     })\n",
    "\n",
    "print(json.dumps(res['hits']['hits'], indent=2, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full text search\n",
    "\n",
    "The searches so far have been simple.  \n",
    "Let’s try more advanced full text search. Before starting this next type of search let me insert one more document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"_id\": \"4\",\n",
      "  \"_index\": \"emap\",\n",
      "  \"_primary_term\": 1,\n",
      "  \"_seq_no\": 1,\n",
      "  \"_shards\": {\n",
      "    \"failed\": 0,\n",
      "    \"successful\": 1,\n",
      "    \"total\": 2\n",
      "  },\n",
      "  \"_type\": \"employee\",\n",
      "  \"_version\": 1,\n",
      "  \"result\": \"created\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "e4 = {\"first_name\":\"Marcelo\",\n",
    "      \"last_name\":\"Jones\",\n",
    "      \"age\": 27,\n",
    "      \"about\": \"I love to play football\",\n",
    "      \"interests\": ['sports','music'],}\n",
    "\n",
    "res = es.index(index='emap',\n",
    "               doc_type='employee',\n",
    "               id=4,\n",
    "               document=e4)\n",
    "\n",
    "print(json.dumps(res, indent=2, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = es.search(index='emap',\n",
    "                doc_type='employee',\n",
    "                query={'match':{\"about\":\"play cricket\"}})\n",
    "\n",
    "for hit in res['hits']['hits']:\n",
    "    print(hit['_source']['about']) \n",
    "    print(hit['_score'])\n",
    "    print('**********************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"_id\": \"5\",\n",
      "  \"_index\": \"emap\",\n",
      "  \"_primary_term\": 1,\n",
      "  \"_seq_no\": 0,\n",
      "  \"_shards\": {\n",
      "    \"failed\": 0,\n",
      "    \"successful\": 1,\n",
      "    \"total\": 2\n",
      "  },\n",
      "  \"_type\": \"employee\",\n",
      "  \"_version\": 1,\n",
      "  \"result\": \"created\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "e5 = {\"first_name\":\"Marcos\",\n",
    "      \"last_name\":\"Jones\",\n",
    "      \"age\": 25,\n",
    "      \"about\": \"I love to play volleyball\",\n",
    "      \"interests\": ['sports','music'],}\n",
    "\n",
    "res = es.index(index='emap',\n",
    "               doc_type='employee',\n",
    "               id=5,\n",
    "               document=e5)\n",
    "\n",
    "print(json.dumps(res, indent=2, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = es.search(index='emap',\n",
    "                doc_type='employee',\n",
    "                query={'match':{\"about\":\"play cricket\"}})\n",
    "\n",
    "for hit in res['hits']['hits']:\n",
    "    print(hit['_source']['about']) \n",
    "    print(hit['_score'])\n",
    "    print('**********************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phrase Search\n",
    "\n",
    "Finding individual words in a field is all well and good, but sometimes you want to match exact sequence of words of phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = es.search(index='emap',\n",
    "                doc_type='employee',\n",
    "                query={'match_phrase':{\"about\":\"play cricket\"}})\n",
    "\n",
    "for hit in res['hits']['hits']:\n",
    "    print(hit['_source']['about']) \n",
    "    print(hit['_score'])\n",
    "    print('**********************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregations\n",
    "\n",
    "Elasticsearch has functionality called aggregations, which allowed you to generate sophisticated analytics over your data. It is similar to Group By in SQL, but much more powerful.  \n",
    "\n",
    "[Ref1](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations.html)  \n",
    "[Ref2](https://techoverflow.net/2019/03/17/how-to-fix-elasticsearch-fielddata-is-disabled-on-text-fields-by-default-for-keyword-field/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"_shards\": {\n",
      "    \"failed\": 0,\n",
      "    \"skipped\": 0,\n",
      "    \"successful\": 5,\n",
      "    \"total\": 5\n",
      "  },\n",
      "  \"aggregations\": {\n",
      "    \"all_interests\": {\n",
      "      \"buckets\": [],\n",
      "      \"doc_count_error_upper_bound\": 0,\n",
      "      \"sum_other_doc_count\": 0\n",
      "    }\n",
      "  },\n",
      "  \"hits\": {\n",
      "    \"hits\": [],\n",
      "    \"max_score\": null,\n",
      "    \"total\": 0\n",
      "  },\n",
      "  \"timed_out\": false,\n",
      "  \"took\": 0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "res= es.search(index='emap',\n",
    "               doc_type='employee',\n",
    "               aggs={\"all_interests\": {\"terms\": {\"field\": \"interests.keyword\"}}}\n",
    "              )\n",
    "\n",
    "print(json.dumps(res, indent=2, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting an Index:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.delete(index='emap', ignore=[400, 404])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A [full example](https://towardsdatascience.com/getting-started-with-elasticsearch-in-python-c3598e718380) on scraping and storing in Elastic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(es_object, index_name, search):\n",
    "    res = es_object.search(index=index_name, query=search)\n",
    "    pprint(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(es_object, index_name):\n",
    "    created = False\n",
    "    # index settings\n",
    "    settings = {\n",
    "        \"settings\": {\n",
    "            \"number_of_shards\": 1,\n",
    "            \"number_of_replicas\": 0\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"salads\": {\n",
    "                \"dynamic\": \"strict\",\n",
    "                \"properties\": {\n",
    "                    \"title\": {\n",
    "                        \"type\": \"text\"\n",
    "                    },\n",
    "                    \"submitter\": {\n",
    "                        \"type\": \"text\"\n",
    "                    },\n",
    "                    \"description\": {\n",
    "                        \"type\": \"text\"\n",
    "                    },\n",
    "                    \"calories\": {\n",
    "                        \"type\": \"integer\"\n",
    "                    },\n",
    "                    \"ingredients\": {\n",
    "                        \"type\": \"nested\",\n",
    "                        \"properties\": {\n",
    "                            \"step\": {\"type\": \"text\"}\n",
    "                        }\n",
    "                    },\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    try:\n",
    "        if not es_object.indices.exists(index_name):\n",
    "            # Ignore 400 means to ignore \"Index Already Exist\" error.\n",
    "            es_object.indices.create(index=index_name, ignore=400, document=settings)\n",
    "            print('Created Index')\n",
    "        created = True\n",
    "    except Exception as ex:\n",
    "        print(str(ex))\n",
    "    finally:\n",
    "        return created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_record(elastic_object, index_name, record):\n",
    "    is_stored = True\n",
    "    try:\n",
    "        outcome = elastic_object.index(index=index_name, doc_type='salads', body=record)\n",
    "        print(outcome)\n",
    "    except Exception as ex:\n",
    "        print('Error in indexing data')\n",
    "        print(str(ex))\n",
    "        is_stored = False\n",
    "    finally:\n",
    "        return is_stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_elasticsearch():\n",
    "    _es = None\n",
    "    _es = Elasticsearch([{'host': 'localhost', 'port': 9200}])\n",
    "    if _es.ping():\n",
    "        print('Connected')\n",
    "    else:\n",
    "        print('Could not connect!')\n",
    "    return _es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(u):\n",
    "    title = '-'\n",
    "    submit_by = '-'\n",
    "    description = '-'\n",
    "    calories = 0\n",
    "    ingredients = []\n",
    "    rec = {}\n",
    "\n",
    "    try:\n",
    "        r = requests.get(u, headers=headers)\n",
    "\n",
    "        if r.status_code == 200:\n",
    "            html = r.text\n",
    "            #soup = BeautifulSoup(html, 'lxml')\n",
    "            soup = BeautifulSoup(html, 'html5')\n",
    "            title_section = soup.select('.recipe-summary__h1')\n",
    "            submitter_section = soup.select('.submitter__name')\n",
    "            description_section = soup.select('.submitter__description')\n",
    "            ingredients_section = soup.select('.recipe-ingred_txt')\n",
    "            calories_section = soup.select('.calorie-count')\n",
    "            if calories_section:\n",
    "                calories = calories_section[0].text.replace('cals', '').strip()\n",
    "\n",
    "            if ingredients_section:\n",
    "                for ingredient in ingredients_section:\n",
    "                    ingredient_text = ingredient.text.strip()\n",
    "                    if 'Add all ingredients to list' not in ingredient_text and ingredient_text != '':\n",
    "                        ingredients.append({'step': ingredient.text.strip()})\n",
    "\n",
    "            if description_section:\n",
    "                description = description_section[0].text.strip().replace('\"', '')\n",
    "\n",
    "            if submitter_section:\n",
    "                submit_by = submitter_section[0].text.strip()\n",
    "\n",
    "            if title_section:\n",
    "                title = title_section[0].text\n",
    "\n",
    "            rec = {'title': title, \n",
    "                   'submitter': submit_by, \n",
    "                   'description': description, \n",
    "                   'calories': calories,\n",
    "                   'ingredients': ingredients}\n",
    "            \n",
    "    except Exception as ex:\n",
    "        print('Exception while parsing')\n",
    "        print(str(ex))\n",
    "    finally:\n",
    "        return json.dumps(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36',\n",
    "           'Pragma': 'no-cache'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.allrecipes.com/recipes/96/salad/'\n",
    "\n",
    "r = requests.get(url, headers=headers)\n",
    "if r.status_code == 200:\n",
    "    html = r.text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    links = soup.select('.fixed-recipe-card__h3 a')\n",
    "    #print(links)\n",
    "    if len(links) > 0:\n",
    "        es = connect_elasticsearch()\n",
    "\n",
    "    for link in links:\n",
    "        sleep(2)\n",
    "        result = parse(link['href'])\n",
    "        if es is not None:\n",
    "            if create_index(es, 'recipes'):\n",
    "                out = store_record(es, 'recipes', result)\n",
    "                print('Data indexed successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected\n"
     ]
    }
   ],
   "source": [
    "es = connect_elasticsearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'search_object' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_291984/1661281848.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# search_object = {'_source': ['title'], 'query': {'match': {'calories': '102'}}}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# search_object = {'_source': ['title'], 'query': {'range': {'calories': {'gte': 20}}}}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'recipes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'search_object' is not defined"
     ]
    }
   ],
   "source": [
    "if es is not None:\n",
    "    # search_object = {'query': {'match': {'calories': '102'}}}\n",
    "    # search_object = {'_source': ['title'], 'query': {'match': {'calories': '102'}}}\n",
    "    # search_object = {'_source': ['title'], 'query': {'range': {'calories': {'gte': 20}}}}\n",
    "    search(es, 'recipes', json.dumps(search_object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
